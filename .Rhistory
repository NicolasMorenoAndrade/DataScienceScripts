View(comptilesareas)
ptiles<-comptilesareas[,c("Anio", "Inglptil")]
#minimal df de ptilesgm16
#minimalptilesgm16 <- ptilesgm16[,c("Anio","Indiptil", "Mateptil","Cienptil","Lectptil","Sociptil", "Inglptil")]
minimalptilesgm16 <- ptilesgm16[,c("Anio", "Inglptil")]
View(minimalptilesgm16)
View(ptiles)
ptiles <- rbind(ptiles, minimalptilesgm16)
#names(ptiles) <- c("Anio", "Percentil global","Matemáticas","Ciencias","Lectura crítica","Sociales","Inglés")
names(ptiles) <- c("Anio", "Inglés")
ptiles <- melt(ptiles, id.vars = "Anio", variable.name = "Area", value.name = "Percentil")
ptilesareas <- ptiles
View(ptilesareas)
cortes <- c(1,80,90,95,99,101)
ptilesareas$type <- cut(ptilesareas$Percentil,breaks=cortes,
labels = c("1 a 79","80 a 89","90 a 94","95 a 99", "100"),
ordered_result = TRUE)
count<-ddply(ptilesareas, "Anio", summarise, amount=length(Anio))
count$amount <- count$amount/1
ptilesareas <- ddply(ptilesareas, c("Anio","Area","type"), summarise,
Numest=length(type))
mergetemp <- merge(ptilesareas,count, by="Anio")
ptilesareas <- mergetemp
ptilesareas$percent <- round(ptilesareas$Numest/ptilesareas$amount,2)
ptilesareas$label <- paste0(sprintf("%.0f", 100*ptilesareas$percent), "%")
df <- ptilesareas
df <- ddply(df, .(Anio,Area), transform, pos = (cumsum(percent*100) - (50*percent)))
# Plot
ggplot(df, aes(x = factor(Anio), y = percent*100, fill = type)) +
geom_bar(stat = "identity", width = .7) +
facet_wrap(~Area)+
geom_text(aes(y = pos, label = label), size = 2.5) +
ylab("Porcentaje de estudiantes")+
xlab("Año")+
theme(legend.position="top")+
scale_fill_manual(values = brewer.pal(5,"Spectral"), name="Percentil")+
theme(strip.text.x = element_text(size=10, face = "bold"))+
coord_flip()
df[df$Anio==2016,4]
df[df$Anio==2016,]
dim(df)
dim(comple.cases(df))
dim(complete.cases(df))
length(complete.cases(df))
length(is.na(df))
length(is.na(df$type))
class(df$type)
levels(df$type)
is.na(df$type)
df <- df[!is.na(df$type),]
# Plot
ggplot(df, aes(x = factor(Anio), y = percent*100, fill = type)) +
geom_bar(stat = "identity", width = .7) +
facet_wrap(~Area)+
geom_text(aes(y = pos, label = label), size = 2.5) +
ylab("Porcentaje de estudiantes")+
xlab("Año")+
theme(legend.position="top")+
scale_fill_manual(values = brewer.pal(5,"Spectral"), name="Percentil")+
theme(strip.text.x = element_text(size=10, face = "bold"))+
coord_flip()
saber16A<-read.csv("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/agregados20162.csv",
encoding = "UTF-8")
source('~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Scripts/agrgados20162.R', echo=TRUE)
names(saber16A)
colsmaterias <- c("PROMLECTURACRITICA","PROMMATEMATICA","PROMSOCIALESYCIUDADANAS","PROMCIENCIASNATURALES","PROMINGLES")
apply(saber16A[,colsmaterias],2,mean)
apply(saber16A[,colsmaterias],1,mean)
class(apply(saber16A[,colsmaterias],1,mean))
saber16A$Promediosimple <- apply(saber16A[,colsmaterias],1,mean)
rank16A <- saber16A[order(saber16A$Promediosimple),]
row.names(rank16A)
rank16A$Rprom <- 1:length(saber16A$Promediosimple)
rank16A[rank16A$CODINST==22848,"Rprom"]
rank16A <- saber16A[order(-saber16A$Promediosimple),]
rank16A$Rprom <- 1:length(saber16A$Promediosimple)
rank16A[rank16A$CODINST==22848,"Rprom"]
rank16A[rank16A$CODINST==22848,c("NOMBREINSTITUCION","Rprom")]
2900*1200
1551*2900
1515
1515*3144
-3480000
1515*3144
1515*2900
exit
q()
?read.csv
read.csv("~/Documents/MachineLearning/machine-learning-ex1/ex1/ex1data1.txt", header = FALSE)
houses <- read.csv("~/Documents/MachineLearning/machine-learning-ex1/ex1/ex1data1.txt", header = FALSE)
View(houses)
names(houses) <- c("X","y")
regularmodel <- lm(houses$y~houses$X)
summary(regularmodel)
?predict
predict(regularmodel,c(35000,70000))
predict(regularmodel,newdata = c(35000,70000))
predict(object = regularmodel,newdata = c(35000,70000))
regularmodel <- lm(houses$y~houses$X, data = houses)
summary(regularmodel)
predict(object = regularmodel,newdata = c(35000,70000))
regularmodel <- lm(y~X, data = houses)
summary(regularmodel)
predict(object = regularmodel,newdata = c(35000,70000))
predict(regularmodel, newdata = data.frame(X=c(35000,70000)))
View(houses)
predict(regularmodel, newdata = data.frame(X=c(3.5,7)))
houses <- read.csv("~/Documents/MachineLearning/machine-learning-ex1/ex1/ex1data1.txt", header = FALSE)
names(houses) <- c("X","y")
# Modelo lineal con lm ----------------------------------------------------
regularmodel <- lm(y~X, data = houses)
summary(regularmodel)
predict(regularmodel, newdata = data.frame(X=c(3.5,7)))
3.5
ans*2
3.5*2
plot(houses)
predict(regularmodel, newdata = data.frame(X=c(3.5,7)))*10000
summary(regularmodel)
rm(list=ls())
#load necessary packages
library(Eccolepack)
library(ggplot2)
library(xtable)
library(plotrix)
library(gridExtra)
library(RColorBrewer)
library(reshape2)
library(plyr)
#colegio principal informe GIMNASIO MODERNO 22848
colegiointeres<-22848
#labelnombre colegio
nomcolelabel<- crucecodigos[crucecodigos$Codigocolegio==colegiointeres, "Nomlabel"]
#label tipo de colegio para título etc
tipocollabel <- ""
#lista colegios moderno 22848, campestre 25395,  anglo 19364, nogales 55988
listacolegios<-c(22848, 25395, 19364, 55988)
#lista referencia calendario A san patricio 22004,merani 66845, #clara casas 20149, CAS 79806 , Juan Ramon 23895, Unidad 83758
refcalA <- c(22004, 66845, 19810, 20149, 83758,79806,23895)
colegiointeres<-22848
#labelnombre colegio
nomcolelabel<- crucecodigos[crucecodigos$Codigocolegio==colegiointeres, "Nomlabel"]
#label tipo de colegio para título etc
tipocollabel <- ""
#lista colegios moderno 22848, campestre 25395,  anglo 19364, nogales 55988
listacolegios<-c(22848, 25395, 19364, 55988)
#lista referencia calendario A san patricio 22004,merani 66845, #clara casas 20149, CAS 79806 , Juan Ramon 23895, Unidad 83758
refcalA <- c(22004, 66845, 19810, 20149, 83758,79806,23895)
#lista referencias masculinos cal A cervantes pp agustinos 23747 , cervantes el retiro 46771, emilio 21162, jose joaco 22640,
mascCalA <- c(23747, 46771,22640, 21162)
#key dfs para las GRAFICAS
load("~/Desktop/EccoleRdev/ObjetosEccoleR/ObjetosDataFrames/SaberPro/csv/saberproeccole.RData")
load("~/Desktop/EccoleRdev/ObjetosEccoleR/ObjetosDataFrames/Saber359/csv/sab359.RData")
load("~/Desktop/EccoleRdev/ObjetosEccoleR/ObjetosDataFrames/Saber359/csv/sab359cccn.RData")
load("~/Desktop/EccoleR/DataFrames/rankingseccole.RData")
load("~/Desktop/EccoleR/DataFrames/pindiveccole.RData")
load("~/Desktop/EccoleR/DataFrames/generales.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Julio/newpindiveccole.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Agosto/Notas12131415/csv/modernosdis.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Agosto/Notas12131415/csv/crucemoderno15.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Agosto/Notas12131415/csv/regresionesGM.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Agosto/Notas12131415/csv/regnoveno2015.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Septiembre/Notas12131415/CalificacionesBachillerato2014/notasdecimo14.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/agregadosAyB.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/agrsaber16A.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/agrsaber16B.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/minirankseccoleA.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/minirankseccoleB.RData")
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Noviembre/Datos/graphsgruposcomparacion.RData")
#loads para percentiles 2016
load("~/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Octubre/Scripts/ptileccole.RData")
#csv saber 11 moderno 2016
ptilesgm16 <- read.csv("/home/nicolas/Documents/GMMSaS/Colegios/GimnasioModerno/Moderno2016/Trabajo/Octubre/DatosSandra/resultadosmoderno2016percentiles.csv",
encoding = "UTF-8")
#load("~/Documents/GMMSaS/GMMSaS/Colegios/Cerros/IBdataDP.RData")
#fix nombre columna anio
names(rankingseccole)[names(rankingseccole)=="Año"]<-"Anio"
#fix nombre codigo universidades
names(univinteres)[names(univinteres)=="Codigocolegio"]<-"Codigouni"
#fix noveno13ingl
#str(noveno13ingl)
matsingl <- names(noveno13ingl)[!names(noveno13ingl)%in%c("Codigo","Estudiante","Ingles")]
fixdf <- noveno13ingl[,matsingl]
noveno13ingl[,matsingl] <- sapply(fixdf,function(x) as.numeric(as.character(x)))
noveno13ingl$Ingl9 <- ifelse(is.na(noveno13ingl$Ingles1),noveno13ingl$Ingles2,noveno13ingl$Ingles1)
noveno13ingl$Fran9 <- ifelse(is.na(noveno13ingl$Frances1),noveno13ingl$Ingles2,noveno13ingl$Frances2)
#fix gmInglreg
gmInglreg15 <- gmInglreg15[,c("Ingles","InglesUndecimoGr1","BasicFrenchDef","HerramientasdeIdiomasBasicPortugueseDef")]
names(gmInglreg15)[4] <- "BasicPortugueseDef"
#get rid of NA
noveno13inglmini <- noveno13ingl[,c("Codigo","Estudiante","Ingl9","Fran9","Ingles")]
#key df para la tabla comparativa
#load("~/Documents/GMMSaS/GMMSaS/Colegios/Cerros/PresentacionAdmisiones/advenioeccole.RData")
#Nombres colegios seleccionados
basicos<-generales[generales$Codigocolegio%in%listacolegios,c("Codigocolegio","Telefono1",
"Ciudad")]
infobasicadf<-merge(basicos,crucecodigos[,c("Codigocolegio","Nomlabel")], by="Codigocolegio")
listameses <- list(Jan="Enero", Feb="Febrero", Mar="Marzo", Apr="Abril", May="Mayo", Jun="Junio",
Jul="Julio", Aug="Agosto", Sep="Septiembre", Oct="Octubre", Nov="Noviembre", Dec="Diciembre")
fecha <- as.character(unlist(strsplit(date(), split=" ")))
#------------------------listas--------------------------------
rank_names <- list(
'Ranking'="General",
'RMate'="Matemáticas",
'RLcri'="Lectura crítica",
'RSoci'="Sociales",
'RIngl'="Inglés",
'RCnat'="Ciencias naturales"
)
#labels
listpuestolabels <- list(Puesto="Puesto individual general", Matepto="Puesto individual matemáticas",
Cienpto="Puesto individual ciencias naturales", Lectpto="Puesto individual lectura crítica",
Socipto="Puesto individual sociales", Inglpto="Puesto individual inglés")
#Para graficas tendencias ranking GM
nomcolsRanks <- c("Anio","Codigocolegio",names(rankingseccole)[grep("R", names(rankingseccole))])
#Copia crucecodigos para mantener en el cache
crucecodigos <- crucecodigos
#hacer un solo miniranks
minirankseccole <- rbind(minirankseccoleA,minirankseccoleB[minirankseccoleB$Anio==2016,])
# #adhoc registro duplicado gm 2016?
minirankseccole <- minirankseccole[!(minirankseccole$Codigocolegio==22848&minirankseccole$RSoci==311),]
gmrankings <- minirankseccoleA[minirankseccoleA$Codigocolegio==22848, nomcolsRanks]
rankingseccole(rankingseccole$Codigocolegio=106286)
rankingseccole[rankingseccole$Codigocolegio=106286,]
rankingseccole[rankingseccole$Codigocolegio==106286,]
rm(list=ls())
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/baa")
h5ls("example.h5")
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
A = matrix(1:10, nr=5, nc=2)
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1,2.0, by = 0.1), dim = c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
rm(list=ls())
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1,2.0, by = 0.1), dim = c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L, seq(0,1, length.out = 5),
c("ab", "cde", "fghi", "a", "s"),
stringsAsFacxtors=FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
readA = h5read("example.h5", "foo/A")
readB = h5read("example.h5", "foo/foobaa/B")
readdf = h5read("example.h5", "df")
readA
h5write(12:14, "example.h5", "foo/A", index = list(1:3,1))
h5read("example.h5", "foo/A")
con <- url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ")
htmlcode <- readLines(con)
close(con)
htmlcode
con <- url("https://www.instagram.com/p/BSZ3uDYj6dN3dlHh824ESoiBYJDeh2tNTg8Qes0/")
htmlcode <- readLines(con)
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
con <- url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlcode <- readLines(con)
close(con)
htmlcode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
con <- url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlcode <- readLines(con)
close(con)
htmlcode
con <- url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlcode <- readLines(con)
close(con)
htmlcode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
html
xpathSApply(html, "//td[@id='col_citedby']", xmlValue)
xpathSApply(html, "//td[@id='colcitedby']", xmlValue)
xpathSApply(html, "//td[@id='col-Citedby']", xmlValue)
xpathSApply(html, "//td[@id='col-gsc_a_ca']", xmlValue)
xpathSApply(html, "//td[@id='gsc_a_ca']", xmlValue)
xpathSApply(html, "//td[@id='citationsForm']", xmlValue)
xpathSApply(html, "//td[@id='col-citationsForm']", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
library(httr)
html2 = GET(url)
content2 = content(html2, as="text")
parsedHTML = htmlParse(content2, asText = TRUE)
xpathSApply(html, "//title", xmlValue)
pg1 = GET(http://httpbin.org/basic-auth/user/passwd)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 <- GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("user","passwd"))
pg2
insta <- GET("https://www.instagram.com/p/BSZ3uDYj6dN3dlHh824ESoiBYJDeh2tNTg8Qes0/",
authenticate(uselessconquest,elquijote5.11)
insta <- GET("https://www.instagram.com/p/BSZ3uDYj6dN3dlHh824ESoiBYJDeh2tNTg8Qes0/",
authenticate(uselessconquest,elquijote5.11)
)
insta <- GET("https://www.instagram.com/p/BSZ3uDYj6dN3dlHh824ESoiBYJDeh2tNTg8Qes0/",
authenticate("uselessconquest","elquijote5.11")
insta <- GET("https://www.instagram.com/p/BSZ3uDYj6dN3dlHh824ESoiBYJDeh2tNTg8Qes0/",
authenticate("uselessconquest","elquijote5.11"))
insta
insta
names(pg2)
closeAllConnections()
library(sqldf)
install.packages(sqldf)
install.packages("sqldf")
library(sqldf)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "quiz2data.csv")
acs <- read.csv("quiz2data.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sqldf("select distinct pwgtp1 from acs")
sqldf("select distinct AGEP from acs")
require(httr);require(XML)
URL <- url("http://biostat.jhsph.edu/~jleek/contact.html")
lines <- readLines(URL)
close(URL)
c(nchar(lines[10]), nchar(lines[20]), nchar(lines[30]), nchar(lines[100]))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
fixed <- read.fwf(url, widths, header = FALSE, skip = 4)
View(fixed)
sum(fixed$V8)
swirl
swirl()
library(swirl)
swirl()
bye()
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = T)
wday(this_day, label = TRUE)
now()
this_moment <- now()
this_moment
hour(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 02, seconds = 55)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hour=17, minutes=1)
depart <- update(depart, hour=17, minutes=34)
depart <- update(depart, hours=17, minutes=34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time,arrive)
as.period(how_long)
stopwatch()
setwd("~/Desktop/DataScience/Scripts")
if(!file.exists("./data")) {
dir.create("./data")
}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileURL, destfile = "./data/idahoHousing.csv", method="curl")
idahoData <- read.csv("./data/idahoHousing.csv")
View(idahoData)
names(idahoData)
strsplit(names(idahoData), split = "wgtp")
strsplit(names(idahoData), split = "wgtp")[123]
GDPfileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
EDUfileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(GDPfileURL, destfile = "./data/gdpcontries.csv", method="curl")
download.file(EDUfileURL, destfile = "./data/educontries.csv", method="curl")
gdp <- read.csv("./data/gdpcontries.csv", skip=3)
names(gdp)[1] <- "CountryCode"
names(gdp)[names(gdp)=="US.dollars."] <- "USD"
class(gdp$USD)
gdp <- select(gdp, CountryCode, Ranking, Economy, USD)
library(dplyr)
gdp <- select(gdp, CountryCode, Ranking, Economy, USD)
gdp <- gdp[2:232,]
gdp <- read.csv("./data/gdpcontries.csv", skip=3)
names(gdp)[1] <- "CountryCode"
names(gdp)[names(gdp)=="US.dollars."] <- "USD"
class(gdp$USD)
gdp <- select(gdp, CountryCode, Ranking, Economy, USD)
gdp[gdp$Ranking=="","Ranking"] <- NA
gdp$Ranking <- as.numeric(as.character(gdp$Ranking))
edu <- read.csv("./data/educontries.csv")
gdprank <- gdp[!is.na(gdp$Ranking),]
gdprank$USD <- as.character(gdprank$USD)
gdprank$USD <- gsub(",","", gdprank$USD)
gdprank$USD <- as.numeric(gdprank$USD)
View(gdprank)
mean(gdprank$USD)
View(gdprank)
names(gdprank)[names(gdprank)=="Economy"] <- "countryNames"
grep("^United",gdprank$countryNames)
gdprank[grep("^United",gdprank$countryNames),"countryNames")
gdprank[grep("^United",gdprank$countryNames),"countryNames"]
test <- merge(gdprank,edu, by="CountryCode")
View(test)
View(test)
gdp <- read.csv("./data/gdpcontries.csv", skip=3)
names(gdp)[1] <- "CountryCode"
names(gdp)[names(gdp)=="US.dollars."] <- "USD"
class(gdp$USD)
gdpfull <- gdp
test <- merge(gdpfull,edu, by="CountryCode")
View(test)
grep("[Ff]iscal", test$Special.Notes)
grep("[Ff]iscal( +year)", test$Special.Notes)
grep("[Ff]iscal( +year[^ ]+ +){1,20} [Jj]une", test$Special.Notes)
grep("[Ff]iscal( +year[^ ]+ +){1,20} june", test$Special.Notes)
grep("[Ff]iscal( +year)", test$Special.Notes)
grep("[Ff]iscal( +year)", fiscal)
fiscal <- test$Special.Notes
grep("[Ff]iscal( +year)", fiscal)
haveinfo <- fiscal[grep("[Ff]iscal( +year)", fiscal)]
grep("[Jj]une", haveinfo)
length(grep("[Jj]une", haveinfo))
install.packages(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
class(sampleTimes)
ymd(sampleTimes)
library(lubridate)
ymd(sampleTimes)
qday(sampleTimes)
day(sampleTimes)
?day
wday(sampleTimes)
wday(sampleTimes, label = TRUE)
sampleTimes$weekday <- wday(sampleTimes, label = TRUE)
sampleTimes = index(amzn)
sampleTimes <- as.data.frame(sampleTimes)
sampleTimes$weekday <- wday(sampleTimes$sampleTimes, label = TRUE)
sampleTimes$year <- year(sampleTimes$sampleTimes, label = TRUE)
sampleTimes$year <- year(sampleTimes$sampleTimes)
dim(sampleTimes$year==2012)
length(sampleTimes$year==2012)
sampleTimes$year==2012
sum(sampleTimes$year==2012)
sum(sampleTimes$weekday=="Monday")
sum(sampleTimes$weekday=="Mon")
sum(sampleTimes$year==2012 & sampleTimes$weekday=="Mon")
